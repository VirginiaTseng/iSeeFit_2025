#!/usr/bin/env python3
"""
ä¸“é—¨ç”¨äº Vision Transformer æ¨¡å‹è½¬æ¢ä¸º Core ML çš„è„šæœ¬
å¤„ç† ViT æ¨¡å‹åœ¨ Core ML è½¬æ¢ä¸­çš„å¸¸è§é—®é¢˜
"""

import torch
import coremltools as ct
import torchvision.models as M
import torch.nn as nn
import os
import warnings

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

def create_vit_model(num_classes=101):
    """åˆ›å»º ViT æ¨¡å‹"""
    model = M.vit_b_16(weights=None)
    model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)
    return model

def load_model_weights(model, model_path):
    """åŠ è½½æ¨¡å‹æƒé‡"""
    print(f"Loading weights from: {model_path}")
    
    checkpoint = torch.load(model_path, map_location="cpu")
    print(f"Checkpoint type: {type(checkpoint)}")
    
    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        elif 'model' in checkpoint:
            state_dict = checkpoint['model']
        else:
            state_dict = checkpoint
    else:
        state_dict = checkpoint
    
    # åŠ è½½æƒé‡ï¼Œå…è®¸éƒ¨åˆ†åŒ¹é…
    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
    
    if missing_keys:
        print(f"Missing keys: {len(missing_keys)}")
    if unexpected_keys:
        print(f"Unexpected keys: {len(unexpected_keys)}")
    
    model.eval()
    return model

def test_model(model):
    """æµ‹è¯•æ¨¡å‹"""
    print("Testing model...")
    test_input = torch.randn(1, 3, 224, 224)
    
    with torch.no_grad():
        output = model(test_input)
    
    print(f"Input shape: {test_input.shape}")
    print(f"Output shape: {output.shape}")
    print(f"Output range: [{output.min():.3f}, {output.max():.3f}]")
    
    return True

def convert_with_torchscript(model, output_path):
    """ä½¿ç”¨ TorchScript è½¬æ¢"""
    print("Converting with TorchScript...")
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    example_input = torch.randn(1, 3, 224, 224)
    
    try:
        # å°è¯• scriptï¼ˆæ¯” trace æ›´ç¨³å®šï¼‰
        print("Trying JIT script...")
        scripted_model = torch.jit.script(model)
        
        # è½¬æ¢ä¸º Core ML
        mlmodel = ct.convert(
            scripted_model,
            inputs=[ct.ImageType(
                name="input_image",
                shape=example_input.shape,
                scale=1/255.0,
                bias=[-0.485/0.229, -0.456/0.224, -0.406/0.225]
            )],
            convert_to="neuralnetwork",
            source="pytorch"  # æ˜ç¡®æŒ‡å®šæºæ¡†æ¶
        )
        
        print("âœ… TorchScript conversion successful!")
        return mlmodel
        
    except Exception as e:
        print(f"âŒ TorchScript conversion failed: {e}")
        return None

def convert_direct(model, output_path):
    """ç›´æ¥è½¬æ¢ï¼ˆç»•è¿‡ TorchScriptï¼‰"""
    print("Converting directly...")
    
    try:
        # ç›´æ¥è½¬æ¢æ¨¡å‹
        mlmodel = ct.convert(
            model,
            inputs=[ct.ImageType(
                name="input_image",
                shape=(1, 3, 224, 224),
                scale=1/255.0,
                bias=[-0.485/0.229, -0.456/0.224, -0.406/0.225]
            )],
            convert_to="neuralnetwork",
            source="pytorch"  # æ˜ç¡®æŒ‡å®šæºæ¡†æ¶
        )
        
        print("âœ… Direct conversion successful!")
        return mlmodel
        
    except Exception as e:
        print(f"âŒ Direct conversion failed: {e}")
        return None

def convert_simplified(model, output_path):
    """ç®€åŒ–è½¬æ¢ï¼ˆæœ€å°é…ç½®ï¼‰"""
    print("Converting with simplified settings...")
    
    try:
        # ä½¿ç”¨æœ€ç®€å•çš„é…ç½®
        mlmodel = ct.convert(
            model,
            inputs=[ct.ImageType(
                name="input_image",
                shape=(1, 3, 224, 224)
            )],
            convert_to="neuralnetwork",
            source="pytorch"  # æ˜ç¡®æŒ‡å®šæºæ¡†æ¶
        )
        
        print("âœ… Simplified conversion successful!")
        return mlmodel
        
    except Exception as e:
        print(f"âŒ Simplified conversion failed: {e}")
        return None

def save_model(mlmodel, output_path):
    """ä¿å­˜æ¨¡å‹"""
    print(f"Saving model to: {output_path}")
    
    try:
        mlmodel.save(output_path)
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        print(f"âœ… Model saved successfully!")
        print(f"ğŸ“ File: {output_path}")
        print(f"ğŸ“ Size: {file_size:.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to save model: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Starting ViT to Core ML conversion...")
    
    # é…ç½®
    model_path = "checkpoints/best_model.pt"
    output_path = "Food101_ViT.mlmodel"
    num_classes = 101
    
    try:
        # 1. åˆ›å»ºæ¨¡å‹
        print("Creating ViT model...")
        model = create_vit_model(num_classes)
        
        # 2. åŠ è½½æƒé‡
        model = load_model_weights(model, model_path)
        
        # 3. æµ‹è¯•æ¨¡å‹
        test_model(model)
        
        # 4. å°è¯•ä¸åŒçš„è½¬æ¢æ–¹æ³•
        mlmodel = None
        
        # æ–¹æ³•1: TorchScript
        mlmodel = convert_with_torchscript(model, output_path)
        
        # æ–¹æ³•2: ç›´æ¥è½¬æ¢
        if mlmodel is None:
            mlmodel = convert_direct(model, output_path)
        
        # æ–¹æ³•3: ç®€åŒ–è½¬æ¢
        if mlmodel is None:
            mlmodel = convert_simplified(model, output_path)
        
        # 5. ä¿å­˜æ¨¡å‹
        if mlmodel is not None:
            success = save_model(mlmodel, output_path)
            if success:
                print("ğŸ‰ Conversion completed successfully!")
                return 0
            else:
                print("âŒ Failed to save model")
                return 1
        else:
            print("âŒ All conversion methods failed")
            return 1
            
    except Exception as e:
        print(f"âŒ Conversion failed: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
